{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from dataproc import extract_wvs\n",
    "from dataproc import get_discharge_summaries\n",
    "from dataproc import concat_and_split\n",
    "from dataproc import build_vocab\n",
    "from dataproc import vocab_index_descriptions\n",
    "from dataproc import word_embeddings\n",
    "from constants import MIMIC_4_DIR, MIMIC_4_NOTES_DIR, MIMIC_4_SAVE_DIR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "import csv\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some data processing in a much better way, with a notebook.\n",
    "\n",
    "First, let's define some stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = 'full' #use all available labels in the dataset for prediction\n",
    "notes_file = f'{MIMIC_4_NOTES_DIR}/note/discharge.csv' # raw note events downloaded from MIMIC-III\n",
    "vocab_size = 'full' #don't limit the vocab size to a specific number\n",
    "vocab_min = 3 #discard tokens appearing in fewer than this many documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine diagnosis and procedure codes and reformat them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes in MIMIC-III are given in separate files for procedures and diagnoses, and the codes are given without periods, which might lead to collisions if we naively combine them. So we have to add the periods back in the right place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfproc = pd.read_csv(f'{MIMIC_4_DIR}/hosp/procedures_icd.csv.gz', compression=\"gzip\",\n",
    "                     dtype={\"icd_code\": str})\n",
    "dfdiag = pd.read_csv(f'{MIMIC_4_DIR}/hosp/diagnoses_icd.csv.gz', compression=\"gzip\",\n",
    "                     dtype={\"icd_code\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfproc=dfproc[dfproc['icd_version']==10]\n",
    "dfdiag=dfdiag[dfdiag['icd_version']==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfdiag['absolute_code'] = dfdiag['icd_code']\n",
    "dfproc['absolute_code'] = dfproc['icd_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcodes = pd.concat([dfdiag, dfproc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcodes.rename(columns={\"subject_id\": \"SUBJECT_ID\",\n",
    "                        \"hadm_id\": \"HADM_ID\",\n",
    "                        \"seq_num\": \"SEQ_NUM\",\n",
    "                        \"icd_code\": \"ICD_CODE\"},\n",
    "                        inplace=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcodes.to_csv('%s/ALL_CODES.csv' % MIMIC_4_SAVE_DIR, index=False,\n",
    "               columns=['SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'absolute_code'],\n",
    "               header=['SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'ICD_CODE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many codes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the full dataset (not just discharge summaries)\n",
    "df = pd.read_csv('%s/ALL_CODES.csv' % MIMIC_4_SAVE_DIR, dtype={\"ICD_CODE\": str})\n",
    "len(df['ICD_CODE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and preprocess raw text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing time!\n",
    "\n",
    "This will:\n",
    "- Select only discharge summaries and their addenda\n",
    "- remove punctuation and numeric-only tokens, removing 500 but keeping 250mg\n",
    "- lowercase all tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the outer module\n",
    "outer_module = importlib.import_module('dataproc')\n",
    "\n",
    "# Get the inner module from the outer module\n",
    "inner_module = getattr(outer_module, 'get_discharge_summaries')\n",
    "\n",
    "# Reload the inner module\n",
    "get_discharge_summaries = importlib.reload(inner_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This reads all notes, selects only the discharge summaries, and tokenizes them, returning the output filename\n",
    "disch_full_file = get_discharge_summaries.write_discharge_summaries(out_file=\"%s/disch_full.csv\" % MIMIC_4_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read this in and see what kind of data we're working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('%s/disch_full.csv' % MIMIC_4_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331794"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many admissions?\n",
    "len(df['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2180-05-07 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>2180-06-27 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>2180-08-07 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>2180-07-25 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000084</td>\n",
       "      <td>23052089</td>\n",
       "      <td>2160-11-25 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331789</th>\n",
       "      <td>19999828</td>\n",
       "      <td>25744818</td>\n",
       "      <td>2149-01-18 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331790</th>\n",
       "      <td>19999828</td>\n",
       "      <td>29734428</td>\n",
       "      <td>2147-08-04 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331791</th>\n",
       "      <td>19999840</td>\n",
       "      <td>21033226</td>\n",
       "      <td>2164-09-17 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331792</th>\n",
       "      <td>19999840</td>\n",
       "      <td>26071774</td>\n",
       "      <td>2164-07-28 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331793</th>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>2145-11-11 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331794 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SUBJECT_ID   HADM_ID            CHARTTIME  \\\n",
       "0         10000032  22595853  2180-05-07 00:00:00   \n",
       "1         10000032  22841357  2180-06-27 00:00:00   \n",
       "2         10000032  25742920  2180-08-07 00:00:00   \n",
       "3         10000032  29079034  2180-07-25 00:00:00   \n",
       "4         10000084  23052089  2160-11-25 00:00:00   \n",
       "...            ...       ...                  ...   \n",
       "331789    19999828  25744818  2149-01-18 00:00:00   \n",
       "331790    19999828  29734428  2147-08-04 00:00:00   \n",
       "331791    19999840  21033226  2164-09-17 00:00:00   \n",
       "331792    19999840  26071774  2164-07-28 00:00:00   \n",
       "331793    19999987  23865745  2145-11-11 00:00:00   \n",
       "\n",
       "                                                     TEXT  \n",
       "0       name ___ unit no ___ admission date ___ discha...  \n",
       "1       name ___ unit no ___ admission date ___ discha...  \n",
       "2       name ___ unit no ___ admission date ___ discha...  \n",
       "3       name ___ unit no ___ admission date ___ discha...  \n",
       "4       name ___ unit no ___ admission date ___ discha...  \n",
       "...                                                   ...  \n",
       "331789  name ___ unit no ___ admission date ___ discha...  \n",
       "331790  name ___ unit no ___ admission date ___ discha...  \n",
       "331791  name ___ unit no ___ admission date ___ discha...  \n",
       "331792  name ___ unit no ___ admission date ___ discha...  \n",
       "331793  name ___ unit no ___ admission date ___ discha...  \n",
       "\n",
       "[331794 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tokens and types\n",
    "types = set()\n",
    "num_tok = 0\n",
    "for row in df.itertuples():\n",
    "    for w in row[4].split():\n",
    "        types.add(w)\n",
    "        num_tok += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num types\", len(types))\n",
    "print(\"Num tokens\", str(num_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's sort by SUBJECT_ID and HADM_ID to make a correspondence with the MIMIC-3 label file\n",
    "df = df.sort_values(['SUBJECT_ID', 'HADM_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the label file by the same\n",
    "dfl = pd.read_csv('%s/ALL_CODES.csv' % MIMIC_4_SAVE_DIR)\n",
    "dfl = dfl.sort_values(['SUBJECT_ID', 'HADM_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331794, 154076)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['HADM_ID'].unique()), len(dfl['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate labels with set of discharge summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there were some HADM_ID's that didn't have discharge summaries, so they weren't included with our notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's filter out these HADM_ID's\n",
    "hadm_ids = set(df['HADM_ID'])\n",
    "with open('%s/ALL_CODES.csv' % MIMIC_4_SAVE_DIR, 'r') as lf:\n",
    "    with open('%s/ALL_CODES_filtered.csv' % MIMIC_4_SAVE_DIR, 'w') as of:\n",
    "        w = csv.writer(of)\n",
    "        w.writerow(['SUBJECT_ID', 'HADM_ID', 'ICD_CODE', 'ADMITTIME', 'DISCHTIME'])\n",
    "        r = csv.reader(lf)\n",
    "        #header\n",
    "        next(r)\n",
    "        for i,row in enumerate(r):\n",
    "            hadm_id = int(row[1])\n",
    "            #print(hadm_id)\n",
    "            #break\n",
    "            if hadm_id in hadm_ids:\n",
    "                w.writerow(row[:2] + [row[-1], '', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = pd.read_csv('%s/ALL_CODES_filtered.csv' % MIMIC_4_SAVE_DIR, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122317"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfl['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's filter out these HADM_ID in the note but not in the label\n",
    "hadm_lids = set(dfl['HADM_ID'])\n",
    "with open(f'{MIMIC_4_SAVE_DIR}/disch_full.csv', 'r', encoding='utf-8') as lf:\n",
    "    with open(f'{MIMIC_4_SAVE_DIR}/disch_full_filtered.csv','w', encoding='utf-8') as of:\n",
    "        w = csv.writer(of)\n",
    "        w.writerow(['SUBJECT_ID', 'HADM_ID', 'CHARTTIME', 'TEXT'])\n",
    "        r = csv.reader(lf)\n",
    "        #header\n",
    "        next(r)\n",
    "        for i,row in enumerate(r):\n",
    "            hadm_id = int(row[1])\n",
    "            #print(hadm_id)\n",
    "            #break\n",
    "            if hadm_id in hadm_lids:\n",
    "                w.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we still need to sort it by HADM_ID\n",
    "dfl = dfl.sort_values(['SUBJECT_ID', 'HADM_ID'])\n",
    "dfl.to_csv('%s/ALL_CODES_filtered.csv' % MIMIC_4_SAVE_DIR, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append labels to notes in a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's append each instance with all of its codes\n",
    "#this is pretty non-trivial so let's use this script I wrote, which requires the notes to be written to file\n",
    "df = pd.read_csv(f'{MIMIC_4_SAVE_DIR}/disch_full_filtered.csv', index_col=None, encoding='utf-8', engine='python')\n",
    "df = df.sort_values(['SUBJECT_ID', 'HADM_ID'])\n",
    "sorted_file = f'{MIMIC_4_SAVE_DIR}/disch_full_filtered.csv'\n",
    "df.to_csv(sorted_file, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the outer module\n",
    "outer_module = importlib.import_module('dataproc')\n",
    "\n",
    "# Get the inner module from the outer module\n",
    "inner_module = getattr(outer_module, 'concat_and_split')\n",
    "\n",
    "# Reload the inner module\n",
    "concat_and_split = importlib.reload(inner_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONCATENATING\n",
      "0 done\n",
      "10000 done\n",
      "20000 done\n",
      "30000 done\n",
      "40000 done\n",
      "50000 done\n",
      "60000 done\n",
      "70000 done\n",
      "80000 done\n",
      "90000 done\n",
      "100000 done\n",
      "110000 done\n",
      "120000 done\n"
     ]
    }
   ],
   "source": [
    "labeled = concat_and_split.concat_data('%s/ALL_CODES_filtered.csv' % MIMIC_4_SAVE_DIR, sorted_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000084</td>\n",
       "      <td>23052089</td>\n",
       "      <td>2160-11-25 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000117</td>\n",
       "      <td>22927623</td>\n",
       "      <td>2181-11-15 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000117</td>\n",
       "      <td>27988844</td>\n",
       "      <td>2183-09-21 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000980</td>\n",
       "      <td>20897796</td>\n",
       "      <td>2193-08-17 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000980</td>\n",
       "      <td>25911675</td>\n",
       "      <td>2191-05-24 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122312</th>\n",
       "      <td>19999784</td>\n",
       "      <td>29355057</td>\n",
       "      <td>2119-10-23 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122313</th>\n",
       "      <td>19999784</td>\n",
       "      <td>29889147</td>\n",
       "      <td>2120-10-31 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122314</th>\n",
       "      <td>19999784</td>\n",
       "      <td>29956342</td>\n",
       "      <td>2121-02-05 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122315</th>\n",
       "      <td>19999828</td>\n",
       "      <td>25744818</td>\n",
       "      <td>2149-01-18 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122316</th>\n",
       "      <td>19999828</td>\n",
       "      <td>29734428</td>\n",
       "      <td>2147-08-04 00:00:00</td>\n",
       "      <td>name ___ unit no ___ admission date ___ discha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122317 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SUBJECT_ID   HADM_ID            CHARTTIME  \\\n",
       "0         10000084  23052089  2160-11-25 00:00:00   \n",
       "1         10000117  22927623  2181-11-15 00:00:00   \n",
       "2         10000117  27988844  2183-09-21 00:00:00   \n",
       "3         10000980  20897796  2193-08-17 00:00:00   \n",
       "4         10000980  25911675  2191-05-24 00:00:00   \n",
       "...            ...       ...                  ...   \n",
       "122312    19999784  29355057  2119-10-23 00:00:00   \n",
       "122313    19999784  29889147  2120-10-31 00:00:00   \n",
       "122314    19999784  29956342  2121-02-05 00:00:00   \n",
       "122315    19999828  25744818  2149-01-18 00:00:00   \n",
       "122316    19999828  29734428  2147-08-04 00:00:00   \n",
       "\n",
       "                                                     TEXT  \n",
       "0       name ___ unit no ___ admission date ___ discha...  \n",
       "1       name ___ unit no ___ admission date ___ discha...  \n",
       "2       name ___ unit no ___ admission date ___ discha...  \n",
       "3       name ___ unit no ___ admission date ___ discha...  \n",
       "4       name ___ unit no ___ admission date ___ discha...  \n",
       "...                                                   ...  \n",
       "122312  name ___ unit no ___ admission date ___ discha...  \n",
       "122313  name ___ unit no ___ admission date ___ discha...  \n",
       "122314  name ___ unit no ___ admission date ___ discha...  \n",
       "122315  name ___ unit no ___ admission date ___ discha...  \n",
       "122316  name ___ unit no ___ admission date ___ discha...  \n",
       "\n",
       "[122317 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['SUBJECT_ID', 'HADM_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD_CODE</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000084</td>\n",
       "      <td>23052089</td>\n",
       "      <td>G3183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000084</td>\n",
       "      <td>23052089</td>\n",
       "      <td>F0280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000084</td>\n",
       "      <td>23052089</td>\n",
       "      <td>R441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000084</td>\n",
       "      <td>23052089</td>\n",
       "      <td>R296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000084</td>\n",
       "      <td>23052089</td>\n",
       "      <td>E785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974461</th>\n",
       "      <td>19999828</td>\n",
       "      <td>29734428</td>\n",
       "      <td>0HR7X74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974462</th>\n",
       "      <td>19999828</td>\n",
       "      <td>29734428</td>\n",
       "      <td>0HBJXZZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974463</th>\n",
       "      <td>19999828</td>\n",
       "      <td>29734428</td>\n",
       "      <td>0HBHXZZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974464</th>\n",
       "      <td>19999828</td>\n",
       "      <td>29734428</td>\n",
       "      <td>02HV33Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974465</th>\n",
       "      <td>19999828</td>\n",
       "      <td>29734428</td>\n",
       "      <td>3E0436Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1974466 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SUBJECT_ID   HADM_ID ICD_CODE  ADMITTIME  DISCHTIME\n",
       "0          10000084  23052089    G3183        NaN        NaN\n",
       "1          10000084  23052089    F0280        NaN        NaN\n",
       "2          10000084  23052089     R441        NaN        NaN\n",
       "3          10000084  23052089     R296        NaN        NaN\n",
       "4          10000084  23052089     E785        NaN        NaN\n",
       "...             ...       ...      ...        ...        ...\n",
       "1974461    19999828  29734428  0HR7X74        NaN        NaN\n",
       "1974462    19999828  29734428  0HBJXZZ        NaN        NaN\n",
       "1974463    19999828  29734428  0HBHXZZ        NaN        NaN\n",
       "1974464    19999828  29734428  02HV33Z        NaN        NaN\n",
       "1974465    19999828  29734428  3E0436Z        NaN        NaN\n",
       "\n",
       "[1974466 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl.sort_values(['SUBJECT_ID', 'HADM_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ssd-3t-2/isviridov/mimic4/physionet.org/files/mimiciv/2.2/notes_labeled.csv\n"
     ]
    }
   ],
   "source": [
    "#name of the file we just made\n",
    "print(labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sanity check the combined data we just made. Do we have all hadm id's accounted for, and the same vocab stats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfnl = pd.read_csv(labeled)\n",
    "#Tokens and types\n",
    "types = set()\n",
    "num_tok = 0\n",
    "for row in dfnl.itertuples():\n",
    "    for w in row[3].split():\n",
    "        types.add(w)\n",
    "        num_tok += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num types 188781 num tokens 203251866\n"
     ]
    }
   ],
   "source": [
    "print(\"num types\", len(types), \"num tokens\", num_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122317"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfnl['HADM_ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/dev/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the outer module\n",
    "outer_module = importlib.import_module('dataproc')\n",
    "\n",
    "# Get the inner module from the outer module\n",
    "inner_module = getattr(outer_module, 'concat_and_split')\n",
    "\n",
    "# Reload the inner module\n",
    "concat_and_split = importlib.reload(inner_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLITTING\n",
      "0 read\n",
      "10000 read\n",
      "20000 read\n",
      "30000 read\n",
      "40000 read\n",
      "50000 read\n",
      "60000 read\n",
      "70000 read\n",
      "80000 read\n",
      "90000 read\n",
      "100000 read\n",
      "110000 read\n",
      "120000 read\n"
     ]
    }
   ],
   "source": [
    "fname = '%s/notes_labeled.csv' % MIMIC_4_SAVE_DIR\n",
    "base_name = \"%s/disch\" % MIMIC_4_SAVE_DIR #for output\n",
    "tr, dv, te = concat_and_split.split_data(fname, base_name=base_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocabulary from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in data...\n",
      "removing rare terms\n",
      "69972 terms qualify out of 179131 total\n",
      "writing output\n"
     ]
    }
   ],
   "source": [
    "vocab_min = 3\n",
    "vname = '%s/vocab.csv' % MIMIC_4_SAVE_DIR\n",
    "build_vocab.build_vocab(vocab_min, tr, vname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sort each data split by length for batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for splt in ['train', 'dev', 'test']:\n",
    "    filename = '%s/disch_%s_split.csv' % (MIMIC_4_SAVE_DIR, splt)\n",
    "    df = pd.read_csv(filename)\n",
    "    df['length'] = df.apply(lambda row: len(str(row['TEXT']).split()), axis=1)\n",
    "    df = df.sort_values(['length'])\n",
    "    df.to_csv('%s/%s_full.csv' % (MIMIC_4_SAVE_DIR, splt), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train word embeddings on all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the outer module\n",
    "outer_module = importlib.import_module('dataproc')\n",
    "\n",
    "# Get the inner module from the outer module\n",
    "inner_module = getattr(outer_module, 'vocab_index_descriptions')\n",
    "\n",
    "# Reload the inner module\n",
    "vocab_index_descriptions = importlib.reload(inner_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building word2vec vocab on /media/ssd-3t-2/isviridov/mimic4/orig_mimic_prepared/disch_full.csv...\n",
      "training...\n",
      "writing embeddings to /media/ssd-3t-2/isviridov/mimic4/orig_mimic_prepared/processed_full.w2v\n"
     ]
    }
   ],
   "source": [
    "w2v_file = word_embeddings.word_embeddings('full', '%s/disch_full.csv' % MIMIC_4_SAVE_DIR, 100, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write pre-trained word embeddings with new vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69972/69972 [00:00<00:00, 130011.40it/s]\n"
     ]
    }
   ],
   "source": [
    "extract_wvs.gensim_to_embeddings('%s/processed_full.w2v' % MIMIC_4_SAVE_DIR, '%s/vocab.csv' % MIMIC_4_SAVE_DIR, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process code descriptions using the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datasets' has no attribute 'load_code_descriptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vocab_index_descriptions\u001b[39m.\u001b[39;49mvocab_index_descriptions(\u001b[39m'\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m/vocab.csv\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m MIMIC_4_SAVE_DIR,\n\u001b[1;32m      2\u001b[0m                                                   \u001b[39m'\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m/description_vectors.vocab\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m MIMIC_4_SAVE_DIR)\n",
      "File \u001b[0;32m/media/ssd-3t-2/isviridov/mimic4/caml-mimic/notebooks/../dataproc/vocab_index_descriptions.py:24\u001b[0m, in \u001b[0;36mvocab_index_descriptions\u001b[0;34m(vocab_file, vectors_file)\u001b[0m\n\u001b[1;32m     22\u001b[0m ind2w \u001b[39m=\u001b[39m {i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:w \u001b[39mfor\u001b[39;00m i,w \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39msorted\u001b[39m(vocab))}\n\u001b[1;32m     23\u001b[0m w2ind \u001b[39m=\u001b[39m {w:i \u001b[39mfor\u001b[39;00m i,w \u001b[39min\u001b[39;00m ind2w\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m---> 24\u001b[0m desc_dict \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mload_code_descriptions()\n\u001b[1;32m     26\u001b[0m tokenizer \u001b[39m=\u001b[39m RegexpTokenizer(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(vectors_file, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m of:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'datasets' has no attribute 'load_code_descriptions'"
     ]
    }
   ],
   "source": [
    "vocab_index_descriptions.vocab_index_descriptions('%s/vocab.csv' % MIMIC_4_SAVE_DIR,\n",
    "                                                  '%s/description_vectors.vocab' % MIMIC_4_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter each split to the top 50 diagnosis/procedure codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first calculate the top k\n",
    "counts = Counter()\n",
    "dfnl = pd.read_csv('%s/notes_labeled.csv' % MIMIC_4_SAVE_DIR)\n",
    "for row in dfnl.itertuples():\n",
    "    for label in str(row[4]).split(';'):\n",
    "        counts[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codes_50 = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codes_50 = [code[0] for code in codes_50[:Y]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E785',\n",
       " 'I10',\n",
       " 'Z87891',\n",
       " 'K219',\n",
       " 'F329',\n",
       " 'I2510',\n",
       " 'N179',\n",
       " 'F419',\n",
       " 'Z7901',\n",
       " 'Z794',\n",
       " 'E039',\n",
       " 'E119',\n",
       " 'G4733',\n",
       " 'D649',\n",
       " 'E669',\n",
       " 'I4891',\n",
       " 'F17210',\n",
       " 'Y929',\n",
       " 'Z66',\n",
       " 'J45909',\n",
       " 'Z7902',\n",
       " 'J449',\n",
       " 'D62',\n",
       " '02HV33Z',\n",
       " 'N390',\n",
       " 'I129',\n",
       " 'E1122',\n",
       " 'E871',\n",
       " 'I252',\n",
       " 'N189',\n",
       " 'E872',\n",
       " 'Z8673',\n",
       " 'Z955',\n",
       " 'Z86718',\n",
       " 'G8929',\n",
       " 'I110',\n",
       " 'K5900',\n",
       " 'N400',\n",
       " 'N183',\n",
       " 'I480',\n",
       " 'I130',\n",
       " 'G4700',\n",
       " 'D696',\n",
       " 'Z951',\n",
       " 'M109',\n",
       " 'Y92239',\n",
       " 'J9601',\n",
       " 'J189',\n",
       " 'Z23',\n",
       " 'Y92230']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('%s/TOP_%s_CODES.csv' % (MIMIC_4_SAVE_DIR, str(Y)), 'w') as of:\n",
    "    w = csv.writer(of)\n",
    "    for code in codes_50:\n",
    "        w.writerow([code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for splt in ['train', 'dev', 'test']:\n",
    "    print(splt)\n",
    "    hadm_ids = set()\n",
    "    with open('%s/%s_50_hadm_ids.csv' % (MIMIC_4_SAVE_DIR, splt), 'r') as f:\n",
    "        for line in f:\n",
    "            hadm_ids.add(line.rstrip())\n",
    "    with open('%s/notes_labeled.csv' % MIMIC_4_SAVE_DIR, 'r') as f:\n",
    "        with open('%s/%s_%s.csv' % (MIMIC_4_SAVE_DIR, splt, str(Y)), 'w') as of:\n",
    "            r = csv.reader(f)\n",
    "            w = csv.writer(of)\n",
    "            #header\n",
    "            w.writerow(next(r))\n",
    "            i = 0\n",
    "            for row in r:\n",
    "                hadm_id = row[1]\n",
    "                if hadm_id not in hadm_ids:\n",
    "                    continue\n",
    "                codes = set(str(row[3]).split(';'))\n",
    "                filtered_codes = codes.intersection(set(codes_50))\n",
    "                if len(filtered_codes) > 0:\n",
    "                    w.writerow(row[:3] + [';'.join(filtered_codes)])\n",
    "                    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for splt in ['train', 'dev', 'test']:\n",
    "    filename = '%s/%s_%s.csv' % (MIMIC_4_SAVE_DIR, splt, str(Y))\n",
    "    df = pd.read_csv(filename)\n",
    "    df['length'] = df.apply(lambda row: len(str(row['TEXT']).split()), axis=1)\n",
    "    df = df.sort_values(['length'])\n",
    "    df.to_csv('%s/%s_%s.csv' % (MIMIC_4_SAVE_DIR, splt, str(Y)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ПЕРЕВЕСТИ DATAFRAME в JSON БЕЗ ADDITION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
